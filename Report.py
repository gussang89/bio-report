import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
from datetime import datetime, timedelta

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("API í‚¤ ì„¤ì • ì—ëŸ¬: Secretsì— GOOGLE_API_KEYê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- 2. ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ (ê¸°ê°„ í™•ì¥ ëŒ€ì‘) ---
def get_recent_papers(keywords, days):
    """
    ì§€ì •ëœ ê¸°ê°„(ì¼ìˆ˜) ë‚´ì˜ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    # ê¸°ê°„ì´ ê¸¸ì–´ì§€ë©´ ì—°ë„ ë²”ìœ„ë„ ë„“ì–´ì•¼ í•˜ë¯€ë¡œ 2ë…„ì¹˜(ì˜¬í•´, ì‘ë…„)ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤.
    current_year = datetime.now().year
    year_range = f"{current_year-1}-{current_year}"
    
    combined_query = " | ".join(keywords)
    
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {
        "query": combined_query,
        "year": year_range,
        "limit": 100,  # ê¸°ê°„ì´ ëŠ˜ì–´ë‚œ ë§Œí¼ ê²€ìƒ‰ í•œë„ë¥¼ 50 -> 100ê°œë¡œ ëŠ˜ë¦¼
        "fields": "title,abstract,url,publicationDate,venue"
    }
    
    response = requests.get(base_url, params=params)
    filtered_papers = []
    
    if response.status_code == 200:
        data = response.json().get('data', [])
        # ì˜¤ëŠ˜ ë‚ ì§œì—ì„œ 'days'ë§Œí¼ ëº€ ë‚ ì§œë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì„¤ì •
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for paper in data:
            pub_date_str = paper.get('publicationDate')
            if pub_date_str:
                try:
                    pub_date = datetime.strptime(pub_date_str, '%Y-%m-%d')
                    if pub_date >= cutoff_date:
                        filtered_papers.append(paper)
                except ValueError:
                    continue
    return filtered_papers

# --- 3. ì œë¯¸ë‚˜ì´ ìš”ì•½ í•¨ìˆ˜ ---
def generate_monthly_report(papers, keywords, months):
    if not papers:
        return "ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    # ë…¼ë¬¸ì´ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ìƒìœ„ 40ê°œê¹Œì§€ ë¶„ì„ (Gemini FlashëŠ” ì»¨í…ìŠ¤íŠ¸ê°€ í¼)
    target_papers = papers[:40]
    
    combined_abstracts = ""
    for i, p in enumerate(target_papers):
        combined_abstracts += f"[{i+1}] {p['title']} ({p.get('publicationDate')}): {p.get('abstract', 'No abstract')} \n\n"

    keyword_str = ", ".join(keywords)

    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€ ê³µì • ìˆ˜ì„ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ê´€ì‹¬ ìˆì–´ í•˜ëŠ” í‚¤ì›Œë“œëŠ” [{keyword_str}] ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ì§€ë‚œ {months}ê°œì›”ê°„ ë°œí‘œëœ ë…¼ë¬¸ë“¤ì˜ ì´ˆë¡ì…ë‹ˆë‹¤.
    
    ì´ ë‚´ìš©ë“¤ì„ ì¢…í•©í•˜ì—¬ í•œêµ­ì–´ë¡œ 'ì›”ê°„ ê¸°ìˆ  íŠ¸ë Œë“œ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³ , ê¸´ ê¸°ê°„ì˜ ê¸°ìˆ  íë¦„ ë³€í™”ë¥¼ ì½ì–´ë‚´ì„¸ìš”.
    
    [ë³´ê³ ì„œ í˜•ì‹]
    1. ğŸ“… **ê¸°ê°„ ë¶„ì„ ({months}ê°œì›”ê°„ì˜ íë¦„)**: ì´ ê¸°ê°„ ë™ì•ˆ ì—°êµ¬ íŠ¸ë Œë“œê°€ ì–´ë–»ê²Œ ë³€í™”í–ˆëŠ”ì§€, ì–´ë–¤ ì£¼ì œê°€ ê°€ì¥ í•«í–ˆëŠ”ì§€ ìš”ì•½.
    2. ğŸ­ **ì£¼ìš” ì¹´í…Œê³ ë¦¬ë³„ ë™í–¥**: (ì˜ˆ: ê³µì • ìµœì í™”, ì‹ ê·œ ì´‰ë§¤, ëŒ€ì²´ ì›ë£Œ ë“±ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì„¤ëª…)
    3. ğŸ† **ê¸°ê°„ ë‚´ Best ì—°êµ¬**: í˜„ì—… ì ìš© ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ì€ í•µì‹¬ ë…¼ë¬¸ 3ê°œë¥¼ ì„ ì •í•˜ê³  ì´ìœ ë¥¼ ì„¤ëª….
    
    [ë…¼ë¬¸ ë°ì´í„°]
    {combined_abstracts}
    """

    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(prompt)
    return response.text

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="Bio-Tech Monthly Report", layout="wide")
st.title("ğŸŒ¿ ë°”ì´ì˜¤ ê¸°ìˆ  íŠ¸ë Œë“œ ë¦¬í¬íŠ¸ (ì›”ê°„/ì£¼ê°„)")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")

default_keywords = """Biodiesel production
Sustainable Aviation Fuel (SAF)
HVO process
Transesterification catalyst
Used Cooking Oil (UCO) pretreatment"""

raw_keywords = st.sidebar.text_area(
    "ê²€ìƒ‰ì–´ ì…ë ¥ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„, ìµœëŒ€ 10ê°œ)", 
    value=default_keywords,
    height=200
)

# [ë³€ê²½] ìŠ¬ë¼ì´ë”ë¥¼ 'ì›”' ë‹¨ìœ„ë¡œ ë³€ê²½ (1ê°œì›” ~ 12ê°œì›”)
months_filter = st.sidebar.slider("ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • (ì›”)", 1, 12, 1)

if st.sidebar.button("ë¦¬í¬íŠ¸ ìƒì„±í•˜ê¸° ğŸš€"):
    keyword_list = [k.strip() for k in raw_keywords.split('\n') if k.strip()]
    
    # ì›”ì„ ì¼(days)ë¡œ í™˜ì‚°
    days_converted = months_filter * 30
    
    if not keyword_list:
        st.error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        st.info(f"ìµœê·¼ {months_filter}ê°œì›” ({days_converted}ì¼) ë™ì•ˆì˜ ë…¼ë¬¸ì„ ë¶„ì„í•©ë‹ˆë‹¤...")
        
        with st.spinner('ë°©ëŒ€í•œ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...'):
            recent_papers = get_recent_papers(keyword_list, days=days_converted)
            
            if not recent_papers:
                st.warning(f"ìµœê·¼ {months_filter}ê°œì›” ë™ì•ˆ ë°œê²¬ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¥¼ ì¢€ ë” ë„“ì€ ë²”ìœ„ë¡œ ë°”ê¿”ë³´ì„¸ìš”.")
            else:
                st.success(f"ì´ {len(recent_papers)}ê±´ì˜ ë…¼ë¬¸ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!")
                
                # ì¢…í•© ë¦¬í¬íŠ¸
                st.subheader(f"ğŸ“Š ì§€ë‚œ {months_filter}ê°œì›”ê°„ì˜ ê¸°ìˆ  ë¶„ì„")
                report_content = generate_monthly_report(recent_papers, keyword_list, months_filter)
                st.markdown(report_content)
                
                st.divider()
                
                # ê°œë³„ ë¦¬ìŠ¤íŠ¸
                st.subheader("ğŸ“ ìˆ˜ì§‘ëœ ë…¼ë¬¸ ëª©ë¡")
                # ìµœì‹ ìˆœ ì •ë ¬
                recent_papers.sort(key=lambda x: x.get('publicationDate', ''), reverse=True)
                
                for paper in recent_papers:
                    with st.expander(f"[{paper['publicationDate']}] {paper['title']}"):
                        st.write(f"**ì €ë„:** {paper.get('venue', 'N/A')}")
                        st.write(f"**ë§í¬:** {paper['url']}")
                        st.caption(paper.get('abstract', 'ì´ˆë¡ ì—†ìŒ'))

st.sidebar.markdown("---")
st.sidebar.caption("Powered by Gemini 1.5 Flash & Semantic Scholar")
