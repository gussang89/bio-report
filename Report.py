import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai  # OpenAI ëŒ€ì‹  êµ¬ê¸€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
from datetime import datetime, timedelta

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ---
# Streamlit Secretsì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì™€ ì„¤ì •
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception as e:
    st.error("API í‚¤ ì„¤ì •ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. Secretsì— GOOGLE_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- 2. ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ (Semantic Scholar) ---
def get_recent_papers(query, days=14):
    current_year = datetime.now().year
    year_range = f"{current_year-1}-{current_year}"
    
    url = f"https://api.semanticscholar.org/graph/v1/paper/search?query={query}&year={year_range}&limit=30&fields=title,abstract,url,publicationDate,venue"
    
    response = requests.get(url)
    filtered_papers = []
    
    if response.status_code == 200:
        data = response.json().get('data', [])
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for paper in data:
            pub_date_str = paper.get('publicationDate')
            if pub_date_str:
                try:
                    pub_date = datetime.strptime(pub_date_str, '%Y-%m-%d')
                    if pub_date >= cutoff_date:
                        filtered_papers.append(paper)
                except ValueError:
                    continue
    return filtered_papers

# --- 3. ì œë¯¸ë‚˜ì´ ìš”ì•½ í•¨ìˆ˜ ---
def generate_weekly_report(papers):
    if not papers:
        return "ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    combined_abstracts = ""
    for i, p in enumerate(papers[:20]): # ì œë¯¸ë‚˜ì´ëŠ” ì…ë ¥ì°½ì´ ì»¤ì„œ 20ê°œë„ ê±°ëœ¬í•©ë‹ˆë‹¤
        combined_abstracts += f"[{i+1}] {p['title']}: {p.get('abstract', 'No abstract')} \n\n"

    # ì œë¯¸ë‚˜ì´ì—ê²Œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸
    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€ ê³µì • ìˆ˜ì„ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ìµœê·¼ ë°œí‘œëœ ë°”ì´ì˜¤ë””ì ¤/SAF ê´€ë ¨ ë…¼ë¬¸ë“¤ì˜ ì´ˆë¡ì…ë‹ˆë‹¤.
    
    ì´ ë‚´ìš©ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ 'ì£¼ê°„ ê¸°ìˆ  ë™í–¥ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [í˜•ì‹]
    1. ğŸ’¡ **í•µì‹¬ íŠ¸ë Œë“œ**: ì´ë²ˆ ì£¼ ì—°êµ¬ë“¤ì´ ê³µí†µì ìœ¼ë¡œ ì£¼ëª©í•˜ëŠ” ê¸°ìˆ  í‚¤ì›Œë“œ (3ì¤„ ìš”ì•½)
    2. ğŸ† **ì£¼ëª©í•  ë§Œí•œ ì„±ê³¼**: ìˆ˜ìœ¨ í–¥ìƒ, ë¹„ìš© ì ˆê° ë“± êµ¬ì²´ì  ìˆ˜ì¹˜ê°€ ìˆëŠ” ì—°êµ¬ 2~3ê°œ ì„ ì •
    3. ğŸ­ **í˜„ì¥ ì ìš© ì•„ì´ë””ì–´**: ì‹¤ì œ ê³µì¥ì— ì ìš©í•´ë³¼ ë§Œí•œ ì 
    
    [ë…¼ë¬¸ ë°ì´í„°]
    {combined_abstracts}
    """

    # Gemini 1.5 Flash ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ì €ë ´í•¨)
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(prompt)
    
    return response.text

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="Bio-Tech Report (Gemini)", layout="wide")
st.title("ğŸŒ¿ ì£¼ê°„ ë°”ì´ì˜¤ ê¸°ìˆ  ë¦¬í¬íŠ¸ (Powered by Gemini)")

st.sidebar.header("ì„¤ì •")
search_query = st.sidebar.text_input("ê²€ìƒ‰ì–´", value="Biodiesel production optimization")
days_filter = st.sidebar.slider("ê¸°ê°„ ì„¤ì • (ì¼)", 7, 30, 14)

if st.sidebar.button("ë¦¬í¬íŠ¸ ìƒì„±í•˜ê¸°"):
    with st.spinner('Geminiê°€ ìµœì‹  ë…¼ë¬¸ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...'):
        recent_papers = get_recent_papers(search_query, days=days_filter)
        
        if not recent_papers:
            st.error(f"ìµœê·¼ {days_filter}ì¼ ë™ì•ˆ ë°œí–‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"ì´ {len(recent_papers)}ê±´ì˜ ë…¼ë¬¸ ë°œê²¬!")
            
            # ì¢…í•© ë¦¬í¬íŠ¸
            st.subheader("ğŸ“Š Gemini ê¸°ìˆ  ë¶„ì„")
            report_content = generate_weekly_report(recent_papers)
            st.markdown(report_content)
            
            st.divider()
            
            # ê°œë³„ ë¦¬ìŠ¤íŠ¸
            st.subheader("ğŸ“ ë…¼ë¬¸ ëª©ë¡")
            for paper in recent_papers:
                with st.expander(f"[{paper['publicationDate']}] {paper['title']}"):
                    st.write(f"**ì €ë„:** {paper.get('venue', 'N/A')}")
                    st.write(f"**ë§í¬:** {paper['url']}")
                    st.caption(paper.get('abstract', 'ì´ˆë¡ ì—†ìŒ'))
