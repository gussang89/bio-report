import streamlit as st
import urllib.request
import urllib.parse
import xml.etree.ElementTree as ET
import google.generativeai as genai
from datetime import datetime, timedelta

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ë° ìë™ ëª¨ë¸ ì°¾ê¸° ---
def configure_gemini():
    try:
        if "GOOGLE_API_KEY" in st.secrets:
            api_key = st.secrets["GOOGLE_API_KEY"]
            genai.configure(api_key=api_key)
            
            # [í•µì‹¬] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•´ì„œ 'generateContent' ê¸°ëŠ¥ì´ ìˆëŠ” ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì„ íƒ
            available_models = []
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    available_models.append(m.name)
            
            # ìš°ì„ ìˆœìœ„: 1.5 Flash -> 1.5 Pro -> 1.0 Pro -> ì•„ë¬´ê±°ë‚˜
            preferred_models = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-1.0-pro', 'models/gemini-pro']
            
            selected_model = None
            for pref in preferred_models:
                if pref in available_models:
                    selected_model = pref
                    break
            
            # ì„ í˜¸í•˜ëŠ” ê²Œ ì—†ìœ¼ë©´ ëª©ë¡ì˜ ì²« ë²ˆì§¸ ê²ƒ ì‚¬ìš©
            if not selected_model and available_models:
                selected_model = available_models[0]
                
            return selected_model
            
        else:
            st.error("Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        st.error(f"API ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì´ë¦„ ì €ì¥
MODEL_NAME = configure_gemini()

# --- 2. arXiv ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ ---
def get_arxiv_papers(keywords, months):
    query_parts = [f'all:"{k}"' for k in keywords]
    search_query = " OR ".join(query_parts)
    encoded_query = urllib.parse.quote(search_query)
    
    base_url = f"http://export.arxiv.org/api/query?search_query={encoded_query}&start=0&max_results=15&sortBy=submittedDate&sortOrder=descending"
    
    try:
        with urllib.request.urlopen(base_url) as url:
            data = url.read().decode('utf-8')
            
        root = ET.fromstring(data)
        namespace = {'atom': 'http://www.w3.org/2005/Atom'}
        
        cutoff_date = datetime.now() - timedelta(days=months*30)
        filtered_papers = []
        
        for entry in root.findall('atom:entry', namespace):
            published_str = entry.find('atom:published', namespace).text
            published_date = datetime.strptime(published_str, "%Y-%m-%dT%H:%M:%SZ")
            
            if published_date >= cutoff_date:
                title = entry.find('atom:title', namespace).text.strip().replace('\n', ' ')
                summary = entry.find('atom:summary', namespace).text.strip().replace('\n', ' ')
                link = entry.find('atom:id', namespace).text
                
                filtered_papers.append({
                    "title": title,
                    "abstract": summary,
                    "url": link,
                    "publicationDate": published_date.strftime("%Y-%m-%d")
                })
        
        return filtered_papers

    except Exception as e:
        st.error(f"arXiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# --- 3. ì œë¯¸ë‚˜ì´ ë¦¬í¬íŠ¸ ì‘ì„± ---
def generate_trend_report(papers, keywords, months):
    if not papers:
        return "ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
    
    if not MODEL_NAME:
        return "ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    target_papers = papers[:10]
    combined_text = ""
    for i, p in enumerate(target_papers):
        combined_text += f"[{i+1}] Title: {p['title']}\nAbstract: {p['abstract'][:200]}...\n\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    í‚¤ì›Œë“œ: {', '.join(keywords)}
    
    ì•„ë˜ ë…¼ë¬¸ ì´ˆë¡ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ 'ê¸°ìˆ  ë™í–¥ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [í˜•ì‹]
    1. ğŸ” **ê²°ê³¼ ìš”ì•½**: "ì´ {len(papers)}ê±´ ê²€ìƒ‰ë¨." (ì‚¬ìš© ëª¨ë¸: {MODEL_NAME})
    2. ğŸ’¡ **íŠ¸ë Œë“œ**: ì£¼ìš” ì—°êµ¬ ì£¼ì œ ìš”ì•½.
    3. ğŸš€ **ì£¼ìš” ë…¼ë¬¸**: í•µì‹¬ ë…¼ë¬¸ 2ê°œ ì†Œê°œ.
    
    [ë°ì´í„°]
    {combined_text}
    """
    
    try:
        # ìë™ìœ¼ë¡œ ì°¾ì•„ë‚¸ ëª¨ë¸ ì´ë¦„ ì‚¬ìš©
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({MODEL_NAME}): {e}"

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="ArXiv Bio-Tech Report", layout="wide")
st.title("ğŸ”¬ ìµœì‹  ë°”ì´ì˜¤ ë…¼ë¬¸ íƒìƒ‰ê¸° (Auto-Model)")

if MODEL_NAME:
    st.caption(f"âœ… ì—°ê²°ëœ AI ëª¨ë¸: `{MODEL_NAME}`")
else:
    st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì„¤ì •")
    default_keywords = "Biodiesel\nBiofuel\nSustainable Aviation Fuel"
    keywords_input = st.text_area("ê²€ìƒ‰ì–´ (ì˜ì–´)", value=default_keywords, height=150)
    months = st.slider("ê²€ìƒ‰ ê¸°ê°„ (ê°œì›”)", 1, 24, 12)
    search_btn = st.button("ê²€ìƒ‰ ì‹œì‘ ğŸ”", type="primary")

if search_btn:
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
    
    if not keywords:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë…¼ë¬¸ ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
            papers = get_arxiv_papers(keywords, months)
            
            if not papers:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"ì™„ë£Œ! {len(papers)}ê±´ì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                report = generate_trend_report(papers, keywords, months)
                st.markdown(report)
                
                with st.expander("ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ ë³´ê¸°"):
                    for p in papers:
                        st.write(f"**[{p['publicationDate']}] {p['title']}**")
                        st.caption(f"[ë§í¬]({p['url']})")
