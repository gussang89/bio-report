import streamlit as st
import urllib.request
import urllib.parse
import json
import re
import google.generativeai as genai
from datetime import datetime, timedelta
import io
from docx import Document

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ---
def configure_gemini():
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
        return True
    return False

# --- 2. ìƒëª…/í™”í•™ê³µí•™ ì „ë¬¸ DB (Europe PMC) ê²€ìƒ‰ í•¨ìˆ˜ ---
def get_epmc_papers(keywords, months):
    query_parts = []
    for k in keywords:
        clean_k = k.strip()
        if not clean_k: continue
        # ê° ì¤„ì˜ ê²€ìƒ‰ì–´ë¥¼ ê´„í˜¸ë¡œ ë¬¶ì–´ ì •í™•ë„ë¥¼ ë†’ì„
        query_parts.append(f'({clean_k})')
    
    if not query_parts: return []

    keyword_query = " OR ".join(query_parts)
    
    # ë‚ ì§œ í•„í„°ë§ (ìµœê·¼ Nê°œì›”)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=months*30)
    date_query = f'FIRST_PDATE:[{start_date.strftime("%Y-%m-%d")} TO {end_date.strftime("%Y-%m-%d")}]'
    
    # ìµœì¢… ì¿¼ë¦¬ ì¡°í•©
    full_query = f"({keyword_query}) AND ({date_query})"
    encoded_query = urllib.parse.quote(full_query)
    
    # ì´ˆë¡(Abstract)ì´ í¬í•¨ëœ core ë°ì´í„°ë¥¼ 50ê°œê¹Œì§€ ê°€ì ¸ì˜µë‹ˆë‹¤.
    base_url = f"https://www.ebi.ac.uk/europepmc/webservices/rest/search?query={encoded_query}&format=json&resultType=core&pageSize=50"
    
    try:
        # Europe PMCëŠ” ì°¨ë‹¨ì´ ê±°ì˜ ì—†ì§€ë§Œ, User-Agentë¥¼ ë„£ì–´ ì•ˆì „í•˜ê²Œ ìš”ì²­í•©ë‹ˆë‹¤.
        req = urllib.request.Request(base_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req) as response:
            data = json.loads(response.read().decode('utf-8'))
            
        filtered_papers = []
        results = data.get('resultList', {}).get('result', [])
        
        for p in results:
            title = p.get('title', '')
            abstract = p.get('abstractText', '')
            pub_date = p.get('firstPublicationDate', '')
            doi = p.get('doi')
            pmid = p.get('pmid')
            
            # DOIê°€ ìˆìœ¼ë©´ ìµœìš°ì„ ìœ¼ë¡œ, ì—†ìœ¼ë©´ PMC ìì²´ ë§í¬ ì‚¬ìš©
            link = f"https://doi.org/{doi}" if doi else (f"https://europepmc.org/article/MED/{pmid}" if pmid else "")
            
            # ì œëª©ê³¼ ì´ˆë¡ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ìœ íš¨í•œ ë…¼ë¬¸ë§Œ í•„í„°ë§
            if title and abstract and link:
                # ë°ì´í„°ì— ì„ì—¬ ìˆëŠ” HTML íƒœê·¸(<b>, <i> ë“±) ê¹”ë”í•˜ê²Œ ì œê±°
                clean_abstract = re.sub('<[^<]+>', '', abstract)
                filtered_papers.append({
                    "title": title, "abstract": clean_abstract, "url": link,
                    "publicationDate": pub_date
                })
        return filtered_papers
    except Exception as e:
        st.error(f"Europe PMC ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

# --- 3. ì œë¯¸ë‚˜ì´ ì‹¬ì¸µ ë¦¬í¬íŠ¸ ì‘ì„± ---
def generate_trend_report(papers, keywords, months):
    if not papers: return "ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    target_papers = papers[:30]
    combined_text = ""
    for i, p in enumerate(target_papers):
        combined_text += f"[{i+1}] ì œëª©: {p['title']}\nì´ˆë¡: {p['abstract']}\n\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€(Biodiesel, HVO, SAF) ê³µì • ì„¤ê³„ ë° ìµœì í™”ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ìˆ˜ì„ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.
    ì•„ë˜ëŠ” ìµœê·¼ {months}ê°œì›”ê°„ í™”í•™/ë°”ì´ì˜¤ ì „ë¬¸ DBì—ì„œ ê²€ìƒ‰ëœ ë…¼ë¬¸ {len(papers)}ê±´ì˜ ì œëª©ê³¼ ì´ˆë¡ì…ë‹ˆë‹¤. (ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(keywords)})

    ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ ë° í˜„ì¥ ì‹¤ë¬´ì§„ì—ê²Œ ë³´ê³ í•  **A4 2í˜ì´ì§€ ë¶„ëŸ‰(ì•½ 3000ì ì´ìƒ)ì˜ ë§¤ìš° ìƒì„¸í•˜ê³  ê¹Šì´ ìˆëŠ” 'ì‹¬ì¸µ ê¸°ìˆ  ë™í–¥ ë¦¬í¬íŠ¸'**ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [í•„ìˆ˜ í¬í•¨ ëª©ì°¨ ë° ì‘ì„± ì§€ì¹¨]
    1. ğŸ“ **Executive Summary (ê±°ì‹œì  íŠ¸ë Œë“œ ì´í‰)**
    2. ğŸ”¬ **ì£¼ìš” ê¸°ìˆ  ë° ê³µì • íŠ¸ë Œë“œ ì‹¬ì¸µ ë¶„ì„** (ì¹´í…Œê³ ë¦¬ë³„ ì„¸ë¶„í™”)
    3. ğŸ’¡ **í˜„ì—… ê³µì • ì ìš© ë° ìµœì í™” ì¸ì‚¬ì´íŠ¸** (ìˆ˜ìœ¨ ê°œì„ , ìœ í‹¸ë¦¬í‹° ë¹„ìš© ì ˆê°, í’ˆì§ˆ í–¥ìƒ ë“± ì‹¤ë¬´ì  ì•„ì´ë””ì–´)
    4. ğŸ† **í•µì‹¬ ë…¼ë¬¸ 5ì„  ì‹¬ì¸µ ë¦¬ë·°** (ëª©ì , ì„±ê³¼, ì‹œì‚¬ì )

    [ë…¼ë¬¸ ë°ì´í„°]
    {combined_text}
    """
    
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    except Exception as e:
        return f"âš ï¸ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"

    if not available_models: return "âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤."

    preferred_order = ['models/gemini-1.5-pro', 'models/gemini-1.5-flash', 'models/gemini-pro']
    sorted_models = [m for m in preferred_order if m in available_models] + [m for m in available_models if m not in preferred_order]

    for model_name in sorted_models:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            continue
    return "âš ï¸ ë¶„ì„ ì‹¤íŒ¨."

# --- 4. Word íŒŒì¼ ìƒì„± í•¨ìˆ˜ ---
def create_word_doc(report_text, keywords):
    doc = Document()
    doc.add_heading('ğŸŒ¿ ë°”ì´ì˜¤ ê³µì • ê¸°ìˆ  ì‹¬ì¸µ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸', 0)
    doc.add_paragraph(f"ìƒì„±ì¼ì: {datetime.now().strftime('%Y-%m-%d')}")
    doc.add_paragraph(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(keywords)}")
    doc.add_paragraph("-" * 50)
    
    for line in report_text.split('\n'):
        if line.startswith('###'):
            doc.add_heading(line.replace('###', '').strip(), level=3)
        elif line.startswith('##'):
            doc.add_heading(line.replace('##', '').strip(), level=2)
        elif line.startswith('#'):
            doc.add_heading(line.replace('#', '').strip(), level=1)
        elif line.startswith('**') and line.endswith('**'):
            p = doc.add_paragraph()
            p.add_run(line.replace('**', '')).bold = True
        else:
            doc.add_paragraph(line)
            
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 5. ë©”ì¸ UI ---
st.set_page_config(page_title="Bio-Process Deep Report", layout="wide")
st.title("ğŸŒ¿ ë°”ì´ì˜¤ ê³µì • ê¸°ìˆ  ì‹¬ì¸µ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸")
st.caption("ìƒëª…ê³¼í•™/í™”í•™ê³µí•™ ì „ë¬¸ DB(Europe PMC)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ì„± ë†’ì€ ë…¼ë¬¸ë§Œ ì—„ì„ í•©ë‹ˆë‹¤.")

if not configure_gemini():
    st.error("âŒ Secretsì— GOOGLE_API_KEY ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

with st.sidebar:
    st.header("ì„¤ì •")
    # í™”í•™ ê³µì •ì— ë§ê²Œ ê¸°ë³¸ ê²€ìƒ‰ì–´ ìµœì í™”
    default_keywords = "Biodiesel production\nSustainable Aviation Fuel\nHydrotreated Vegetable Oil\nTransesterification catalyst\nCavitation mixing"
    keywords_input = st.text_area("ê²€ìƒ‰ì–´ (ì˜ì–´)", value=default_keywords, height=200)
    months = st.slider("ê²€ìƒ‰ ê¸°ê°„ (ê°œì›”)", 1, 24, 12)
    search_btn = st.button("ì‹¬ì¸µ ë¦¬í¬íŠ¸ ìƒì„± ğŸš€", type="primary")

if search_btn:
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
    
    with st.spinner("ì „ë¬¸ DBì—ì„œ ë…¼ë¬¸ì„ ìˆ˜ì§‘í•˜ê³ , AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        papers = get_epmc_papers(keywords, months)
        
        if not papers:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¥¼ ì•½ê°„ ìˆ˜ì •í•´ë³´ì„¸ìš”.")
        else:
            st.success(f"ì„±ê³µ! ê´€ë ¨ë„ ë†’ì€ ë…¼ë¬¸ {len(papers)}ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            report = generate_trend_report(papers, keywords, months)
            docx_file = create_word_doc(report, keywords)
            
            st.download_button(
                label="ğŸ“¥ Word íŒŒì¼(.docx)ë¡œ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=docx_file,
                file_name=f"Bio_Process_Report_{datetime.now().strftime('%Y%m%d')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                type="primary"
            )
            
            st.divider()
            
            tab1, tab2 = st.tabs(["ğŸ“Š AI ì‹¬ì¸µ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸", "ğŸ“ ë…¼ë¬¸ ì›ë¬¸ ë¦¬ìŠ¤íŠ¸"])
            
            with tab1:
                st.markdown(report)
            
            with tab2:
                for p in papers:
                    with st.expander(f"{p['title']} ({p['publicationDate']})"):
                        st.write(p['abstract'])
                        st.markdown(f"**[ì›ë¬¸ ë§í¬ (DOI/PMC)]({p['url']})**")
