import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
import time
from datetime import datetime, timedelta

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

# --- 2. ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ (ìºì‹± ì ìš© + ì—ëŸ¬ ë°©ì§€) ---
# @st.cache_data: ì´ ë°ì½”ë ˆì´í„°ê°€ ìˆìœ¼ë©´ ë˜‘ê°™ì€ ê²€ìƒ‰ì–´ëŠ” 1ì‹œê°„(3600ì´ˆ) ë™ì•ˆ APIë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ì €ì¥ëœ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
@st.cache_data(ttl=3600, show_spinner=False)
def get_recent_papers(keywords, months):
    # APIì— ë¬´ë¦¬ë¥¼ ì£¼ì§€ ì•Šê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°
    time.sleep(1)
    
    today = datetime.now()
    cutoff_date = today - timedelta(days=months*30)
    
    # ê²€ìƒ‰ì–´ ê²°í•©
    combined_query = " | ".join(keywords)
    
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •
    current_year = today.year
    year_range = f"{current_year-1}-{current_year}"

    params = {
        "query": combined_query,
        "year": year_range,
        "limit": 100, 
        "fields": "title,abstract,url,publicationDate,venue,citationCount"
    }
    
    try:
        response = requests.get(base_url, params=params)
        
        # 429 ì—ëŸ¬(ë„ˆë¬´ ë§ì€ ìš”ì²­) ì²˜ë¦¬
        if response.status_code == 429:
            st.error("ğŸš¦ API ìš”ì²­ì´ ë„ˆë¬´ ë§ì•„ ì ì‹œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. 1~2ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            return []
            
        if response.status_code != 200:
            st.error(f"ë…¼ë¬¸ ê²€ìƒ‰ API ì˜¤ë¥˜: {response.status_code}")
            return []

        data = response.json().get('data', [])
        
        filtered_papers = []
        for paper in data:
            pub_date_str = paper.get('publicationDate')
            if pub_date_str:
                try:
                    pub_date = datetime.strptime(pub_date_str, '%Y-%m-%d')
                    if pub_date >= cutoff_date:
                        filtered_papers.append(paper)
                except ValueError:
                    continue
        
        # ìµœì‹ ìˆœ ì •ë ¬
        filtered_papers.sort(key=lambda x: x['publicationDate'], reverse=True)
        return filtered_papers

    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- 3. ì œë¯¸ë‚˜ì´ ë¦¬í¬íŠ¸ ì‘ì„± ---
def generate_trend_report(papers, keywords, months):
    if not papers:
        return "ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    target_papers = papers[:20]
    
    combined_text = ""
    for i, p in enumerate(target_papers):
        abstract = p.get('abstract')
        if not abstract:
            abstract = "ì´ˆë¡ ì—†ìŒ"
        combined_text += f"[{i+1}] ë‚ ì§œ: {p['publicationDate']} / ì œëª©: {p['title']} / ì´ˆë¡: {abstract[:200]}...\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€ ê³µì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ì ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(keywords)}
    
    ì•„ë˜ëŠ” ìµœê·¼ {months}ê°œì›”ê°„ ë°œí‘œëœ ê´€ë ¨ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ë¶„ì„í•˜ì—¬ í•œêµ­ì–´ë¡œ 'ê¸°ìˆ  íŠ¸ë Œë“œ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ì‘ì„± í¬ì¸íŠ¸]
    1. ğŸ” **ê²€ìƒ‰ ìš”ì•½**: "ì´ {len(papers)}ê±´ì˜ ìµœì‹  ë…¼ë¬¸ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    2. ğŸ“ˆ **í•µì‹¬ ë™í–¥**: ìµœê·¼ ì—°êµ¬ë“¤ì´ ì§‘ì¤‘í•˜ê³  ìˆëŠ” ì£¼ì œ ìš”ì•½
    3. â­ **ì£¼ëª©í•  ë…¼ë¬¸ 3ì„ **: ì‹¤ìš©ì ì¸ ì—°êµ¬ 3ê°œë¥¼ ì„ ì •í•˜ì—¬ ì´ìœ  ì„¤ëª….
    
    [ë…¼ë¬¸ ë°ì´í„°]
    {combined_text}
    """
    
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(prompt)
    return response.text

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="Bio-Tech Trends", layout="wide")
st.title("ğŸ”¬ ìµœì‹  ë°”ì´ì˜¤ ë…¼ë¬¸ íƒìƒ‰ê¸°")
st.caption("íŒ: ì¦ì€ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ 1~2ë¶„ ì •ë„ ì‰¬ì—ˆë‹¤ê°€ ê²€ìƒ‰í•˜ì„¸ìš”.")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì„¤ì •")
    
    # ê¸°ë³¸ê°’
    default_keywords = "Biodiesel production\nSustainable Aviation Fuel\nTransesterification process"
    
    keywords_input = st.text_area("ê²€ìƒ‰ì–´ (ì˜ì–´, ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)", value=default_keywords, height=150)
    months = st.slider("ê²€ìƒ‰ ê¸°ê°„ (ê°œì›”)", 1, 24, 6)
    
    search_btn = st.button("ê²€ìƒ‰ ì‹œì‘ ğŸ”", type="primary")

# ë©”ì¸ í™”ë©´ ë¡œì§
if search_btn:
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
    
    if not keywords:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner(f"ìµœê·¼ {months}ê°œì›”ê°„ì˜ ë…¼ë¬¸ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
            # ì´ì œ ìºì‹± ë•ë¶„ì— ì¤‘ë³µ í˜¸ì¶œ ì‹œ APIë¥¼ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤!
            papers = get_recent_papers(keywords, months)
            
            if not papers:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•´ë³´ì„¸ìš”.")
            else:
                tab1, tab2 = st.tabs(["ğŸ“Š AI ìš”ì•½ ë¦¬í¬íŠ¸", "ğŸ“ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸"])
                
                with tab1:
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(papers)}ê±´ì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    report = generate_trend_report(papers, keywords, months)
                    st.markdown(report)
                    
                with tab2:
                    for p in papers:
                        with st.expander(f"[{p['publicationDate']}] {p['title']}"):
                            st.write(f"**ì €ë„:** {p.get('venue', 'N/A')}")
                            st.write(f"**ì¸ìš©ìˆ˜:** {p.get('citationCount', 0)}")
                            st.markdown(f"[ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({p['url']})")
                            st.caption(p.get('abstract', 'ì´ˆë¡ ë‚´ìš© ì—†ìŒ'))
