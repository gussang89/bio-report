import streamlit as st
import pandas as pd
import requests
import google.generativeai as genai
from datetime import datetime, timedelta

# --- 1. êµ¬ê¸€ ì œë¯¸ë‚˜ì´ ì„¤ì • ---
try:
    if "GOOGLE_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    else:
        st.error("Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

# --- 2. ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ (í•µì‹¬ ìˆ˜ì •ë¨) ---
def get_recent_papers(keywords, months):
    # 1. ë‚ ì§œ ê¸°ì¤€ ì„¤ì •
    today = datetime.now()
    cutoff_date = today - timedelta(days=months*30)
    
    # 2. ê²€ìƒ‰ì–´ ê²°í•© (OR ì¡°ê±´)
    # ê²€ìƒ‰ì–´ê°€ ë„ˆë¬´ ë³µì¡í•˜ë©´ APIê°€ í—·ê°ˆë ¤í•˜ë¯€ë¡œ, ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ìœ¼ë¡œ í¬ë§·íŒ…
    combined_query = " | ".join(keywords)
    
    # 3. API ìš”ì²­ ì„¤ì •
    base_url = "https://api.semanticscholar.org/graph/v1/paper/search"
    
    # ìµœê·¼ 2ë…„ì¹˜ ë°ì´í„°ì—ì„œ ê²€ìƒ‰ (ê·¸ë˜ì•¼ ì´ë²ˆ ë‹¬ ë…¼ë¬¸ì´ í¬í•¨ë¨)
    current_year = today.year
    year_range = f"{current_year-1}-{current_year}"

    params = {
        "query": combined_query,
        "year": year_range,
        "limit": 100,  # ë„‰ë„‰í•˜ê²Œ 100ê°œ ê°€ì ¸ì˜´
        "fields": "title,abstract,url,publicationDate,venue,citationCount"
        # ì£¼ì˜: ë¬´ë£Œ APIì—ì„œëŠ” 'sort' íŒŒë¼ë¯¸í„°ê°€ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆì–´, 
        # ìµœì‹  ì—°ë„(year_range)ë¥¼ íƒ€ì´íŠ¸í•˜ê²Œ ì¡ê³  íŒŒì´ì¬ì—ì„œ ê±°ë¥´ëŠ” ë°©ì‹ì´ ê°€ì¥ í™•ì‹¤í•©ë‹ˆë‹¤.
    }
    
    try:
        response = requests.get(base_url, params=params)
        
        if response.status_code != 200:
            st.error(f"ë…¼ë¬¸ ê²€ìƒ‰ API ì˜¤ë¥˜: {response.status_code}")
            return []

        data = response.json().get('data', [])
        
        # 4. íŒŒì´ì¬ì—ì„œ ë‚ ì§œ í•„í„°ë§ ë° ì •ë ¬ (ì—¬ê¸°ê°€ ì¤‘ìš”!)
        filtered_papers = []
        for paper in data:
            pub_date_str = paper.get('publicationDate')
            if pub_date_str:
                try:
                    pub_date = datetime.strptime(pub_date_str, '%Y-%m-%d')
                    # ì‚¬ìš©ìê°€ ì„¤ì •í•œ ê¸°ê°„(months) ì´ë‚´ì¸ì§€ í™•ì¸
                    if pub_date >= cutoff_date:
                        filtered_papers.append(paper)
                except ValueError:
                    continue
        
        # 5. ì§„ì§œ ìµœì‹ ìˆœìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        filtered_papers.sort(key=lambda x: x['publicationDate'], reverse=True)
        
        return filtered_papers

    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- 3. ì œë¯¸ë‚˜ì´ ë¦¬í¬íŠ¸ ì‘ì„± ---
def generate_trend_report(papers, keywords, months):
    if not papers:
        return "ë¶„ì„í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

    # ìƒìœ„ 20ê°œ ë…¼ë¬¸ë§Œ ë¶„ì„ (ë„ˆë¬´ ë§ìœ¼ë©´ ìš”ì•½ í’ˆì§ˆ ì €í•˜)
    target_papers = papers[:20]
    
    combined_text = ""
    for i, p in enumerate(target_papers):
        # ì´ˆë¡ì´ ì—†ëŠ” ê²½ìš° ì œëª©ë§Œì´ë¼ë„ ì‚¬ìš©
        abstract = p.get('abstract')
        if not abstract:
            abstract = "ì´ˆë¡ ì—†ìŒ (ì œëª©ìœ¼ë¡œ ìœ ì¶” í•„ìš”)"
        combined_text += f"[{i+1}] ë‚ ì§œ: {p['publicationDate']} / ì œëª©: {p['title']} / ì´ˆë¡: {abstract[:300]}...\n\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ë°”ì´ì˜¤ ì—ë„ˆì§€ ê³µì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ì ê´€ì‹¬ í‚¤ì›Œë“œ: {', '.join(keywords)}
    
    ì•„ë˜ëŠ” ìµœê·¼ {months}ê°œì›”ê°„ ë°œí‘œëœ ê´€ë ¨ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì´ë“¤ì„ ë¶„ì„í•˜ì—¬ í•œêµ­ì–´ë¡œ 'ê¸°ìˆ  íŠ¸ë Œë“œ ë¸Œë¦¬í•‘'ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ì‘ì„± í¬ì¸íŠ¸]
    1. ğŸ” **ê²€ìƒ‰ í˜„í™©**: "ì´ {len(papers)}ê±´ì˜ ìµœì‹  ë…¼ë¬¸ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤." ë¡œ ì‹œì‘í•  ê²ƒ.
    2. ğŸ“ˆ **í•µì‹¬ ë™í–¥**: ìµœê·¼ ì—°êµ¬ë“¤ì´ ì§‘ì¤‘í•˜ê³  ìˆëŠ” ì£¼ì œ (ì˜ˆ: íŠ¹ì • ê³µì • íš¨ìœ¨í™”, ì‹ ê·œ ì´‰ë§¤ ë“±)
    3. â­ **ì£¼ëª©í•  ë…¼ë¬¸ 3ì„ **: ê°€ì¥ ì‹¤ìš©ì ì´ê±°ë‚˜ í¥ë¯¸ë¡œìš´ ì—°êµ¬ 3ê°œë¥¼ ë½‘ì•„ ì œëª©ê³¼ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª….
    
    [ë…¼ë¬¸ ë°ì´í„°]
    {combined_text}
    """
    
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(prompt)
    return response.text

# --- 4. ë©”ì¸ UI ---
st.set_page_config(page_title="Bio-Tech Trends", layout="wide")
st.title("ğŸ”¬ ìµœì‹  ë°”ì´ì˜¤ ë…¼ë¬¸ íƒìƒ‰ê¸°")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì„¤ì •")
    
    # ê¸°ë³¸ê°’
    default_keywords = "Biodiesel\nSustainable Aviation Fuel\nTransesterification"
    
    keywords_input = st.text_area("ê²€ìƒ‰ì–´ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)", value=default_keywords, height=150)
    months = st.slider("ê²€ìƒ‰ ê¸°ê°„ (ê°œì›”)", 1, 24, 6) # ê¸°ë³¸ 6ê°œì›”ë¡œ ëŠ˜ë¦¼
    
    search_btn = st.button("ê²€ìƒ‰ ì‹œì‘ ğŸ”", type="primary")

# ë©”ì¸ í™”ë©´ ë¡œì§
if search_btn:
    keywords = [k.strip() for k in keywords_input.split('\n') if k.strip()]
    
    if not keywords:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner(f"ìµœê·¼ {months}ê°œì›”ê°„ì˜ ë…¼ë¬¸ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
            papers = get_recent_papers(keywords, months)
            
            if not papers:
                st.error("ì¡°ê±´ì— ë§ëŠ” ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ëŠ˜ë¦¬ê±°ë‚˜ ê²€ìƒ‰ì–´ë¥¼ ì˜ì–´ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”.")
                st.info("íŒ: í•œê¸€ ê²€ìƒ‰ì–´ëŠ” ì˜ ê²€ìƒ‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì˜ˆ: ë°”ì´ì˜¤ë””ì ¤ -> Biodiesel)")
            else:
                # íƒ­ìœ¼ë¡œ í™”ë©´ ë¶„ë¦¬
                tab1, tab2 = st.tabs(["ğŸ“Š AI ìš”ì•½ ë¦¬í¬íŠ¸", "ğŸ“ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸"])
                
                with tab1:
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì´ {len(papers)}ê±´ì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    report = generate_trend_report(papers, keywords, months)
                    st.markdown(report)
                    
                with tab2:
                    for p in papers:
                        with st.expander(f"[{p['publicationDate']}] {p['title']}"):
                            st.write(f"**ì €ë„:** {p.get('venue', 'N/A')}")
                            st.write(f"**ì¸ìš©ìˆ˜:** {p.get('citationCount', 0)}")
                            st.markdown(f"[ì›ë¬¸ ë³´ëŸ¬ê°€ê¸°]({p['url']})")
                            st.caption(p.get('abstract', 'ì´ˆë¡ ë‚´ìš© ì—†ìŒ'))
